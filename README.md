# Awesome Hallucination Papers in MLLMs
A curated list of papers about hallucination in multi-modal large language models (MLLMs)

## MLLM's Hallucination Benchmarks
This section collects the benchmark papers on evaluating MLLM's hallucination.

- **Evaluating Object Hallucination in Large Vision-Language Models** [[paper]](https://arxiv.org/pdf/2305.10355.pdf) [[code]](https://github.com/RUCAIBox/POPE)

  `EMNLP 2023`

- *HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models* [[paper]](https://arxiv.org/pdf/2310.14566.pdf) [[code]](https://github.com/tianyi-lab/HallusionBench)

  `Arxiv 2023/10`

- *An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation* [[paper]](https://arxiv.org/pdf/2311.07397.pdf) [[code]](https://github.com/junyangwang0410/AMBER)

  `Arxiv 2023/11`


## Works on Mitigating MLLM's Hallucination
This section collects the papers on mitigating the MLLM's hallucination.

- *Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning* [[paper]](https://arxiv.org/pdf/2306.14565.pdf) [[code]](https://github.com/FuxiaoLiu/LRV-Instruction)

  `Arxiv 2023/07`

- *Detecting and Preventing Hallucinations inLarge Vision Language Models* [[paper]](https://arxiv.org/pdf/2308.06394.pdf) 

  `Arxiv 2023/08`

- *Woodpecker: Hallucination Correction for Multimodal Large Language Models* [[paper]](https://arxiv.org/pdf/2310.16045.pdf) [[code]](https://github.com/BradyFU/Woodpecker)

  `Arxiv 2023/10`

- *Analyzing and Mitigating Object Hallucination in Large Vision-Language Models* [[paper]](https://arxiv.org/pdf/2310.00754.pdf) [[code]](https://github.com/YiyangZhou/LURE)

  `Arxiv 2023/10`

- *HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data* [[paper]](https://arxiv.org/pdf/2311.13614.pdf) [[code]](https://github.com/Yuqifan1117/HalluciDoctor)

  `Arxiv 2023/11`

## Works on Analyzing MLLM's Hallucination
This section collects the papers on analyzing the MLLM's hallucination.

- *Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges* [[paper]](https://arxiv.org/pdf/2311.03287.pdf) [[code]](https://github.com/gzcch/Bingo)

  `Arxiv 2023/11`
  
